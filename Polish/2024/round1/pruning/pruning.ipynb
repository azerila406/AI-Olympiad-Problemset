{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29ff7bc",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Deep Learning is a highly experimental field, and as a result, there can be many satisfactory (though usually non-optimal) solutions for any given problem. It often happens that neural network architectures are disproportionately large for the complexity of the task. It turns out that we can \"slim down\" these models with only a small loss in prediction accuracy.\n",
    "\n",
    "Pruning a network involves removing individual weights or entire neurons. There are many advantages to this method:\n",
    "\n",
    "    Reducing the size of the network.\n",
    "\n",
    "    Speeding up inference.\n",
    "\n",
    "    Counteracting overfitting.\n",
    "\n",
    "    Improving results.\n",
    "\n",
    "To effectively reduce the network's size, we must zero out a sufficient number of elements in its weight matrices. By doing so, we can better compress the model in memory. However, just zeroing out the weights is not enough to speed up inference. It is also necessary to implement and effectively utilize sparse matrix computations. Another pruning method can be the removal of entire neurons, which reduces the actual size of the weight matrices.\n",
    "\n",
    "In this task, we will focus only on zeroing out weights within the model. You cannot change the network's architecture (for example, by removing a neuron or an entire hidden layer). We will consider this problem using a regression example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a2f47",
   "metadata": {},
   "source": [
    "### **Task** 📝\n",
    "\n",
    "Your goal is to implement the function `your_pruning_algorithm(model: torch.nn.Module) -> pruned_model: torch.nn.Module`. This function will take the model implemented below as input and return its **pruned** version.\n",
    "\n",
    "The objective is to have the highest possible number of zeroed-out model parameters (**weights and biases**), while maintaining the lowest possible **mean squared error (MSE)** for its predictions.\n",
    "\n",
    "You'll find a designated cell in the notebook below for your function. The cells you need to modify will be very clearly marked!\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluation**\n",
    "\n",
    "You will be evaluated based on the result of the following function (the higher the value, the better):\n",
    "\n",
    "$$\n",
    "\\mathrm{score}(s, \\epsilon) = \\begin{cases}\n",
    "    0 & \\text{if } \\epsilon > 1000 \\\\\n",
    "    \\left(1 - \\frac{\\epsilon}{1000}\\right)^{1.5} \\cdot s^{1.5} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where:\n",
    "* **$s$** is the number of zeroed parameters divided by the total number of parameters in the model (**sparsity**).\n",
    "* **$\\epsilon$** is the **mean squared error (MSE)** on the test set.\n",
    "\n",
    "This scoring criterion and all the functions mentioned above are already implemented for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9211066",
   "metadata": {},
   "source": [
    "### **Constraints** 📜\n",
    "\n",
    "* Your function must return the model in a **maximum of 5 minutes** when run on Google Colab with a GPU.\n",
    "* The weights file must be saved using the `save_parameters` function with the name `model_parameters.pkl`.\n",
    "* You **cannot change the model's architecture**. It must have exactly:\n",
    "    * An input layer of size 128\n",
    "    * A hidden layer of size 1024\n",
    "    * A Sigmoid activation function\n",
    "    * An output layer of size 10\n",
    "\n",
    "---\n",
    "\n",
    "### **Submission Files** 📁\n",
    "\n",
    "1.  This notebook.\n",
    "2.  The model's parameters (weights), saved using the `save_parameters` function. Do not change the name of the generated file: `model_parameters.pkl`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluation** 📈\n",
    "\n",
    "The weights file you provide will be the basis for your grade. However, you must also submit a working notebook that generates this `model_parameters.pkl` weights file in **under 5 minutes** after running all cells with the `FINAL_EVALUATION_MODE` flag set to `True` (timed on Google Colab with GPU access).\n",
    "\n",
    "For this task, you can earn between **0 and 1.5 points**.\n",
    "* If your score is below **0.085**, you will receive 0 points.\n",
    "* If your score is above **0.95**, you will receive the maximum of 1.5 points.\n",
    "* Between these two thresholds, your points will increase linearly with your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480d9db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FINAL_EVALUATION_MODE = False  # During the evaluation, we will set this flag to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58688b63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ##########################\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1388fe0",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e859e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ###########################\n",
    "\n",
    "# Function to load training and validation data as np.array\n",
    "def load_data_from_file(x_train_path, y_train_path, x_valid_path, y_valid_path):\n",
    "    X_train = np.load(x_train_path)\n",
    "    y_train = np.load(y_train_path)\n",
    "\n",
    "    X_valid = np.load(x_valid_path)\n",
    "    y_valid = np.load(y_valid_path)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "# Dataset class\n",
    "class InMemDataset(Dataset):\n",
    "    def __init__(self, xs, ys, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.dataset = []\n",
    "        for i in tqdm(range(len(xs))):\n",
    "            self.dataset.append((torch.tensor(xs[i]).to(device).float(), torch.tensor(ys[i]).to(device).float() ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8e188",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ###########################\n",
    "\n",
    "# Let's load the data and create dataloaders\n",
    "X_train, y_train, X_valid, y_valid = load_data_from_file(\n",
    "    \"train_data/X_train.npy\",\n",
    "    \"train_data/y_train.npy\",\n",
    "    \"valid_data/X_valid.npy\",\n",
    "    \"valid_data/y_valid.npy\",\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "_train = InMemDataset(X_train, y_train, device)\n",
    "_valid = InMemDataset(X_valid, y_valid, device)\n",
    "\n",
    "loaders = {\n",
    "    \"train\" : DataLoader(_train, batch_size=batch_size, shuffle=True),\n",
    "    \"valid\" : DataLoader(_valid, batch_size=batch_size, shuffle=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62e6bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ###########################\n",
    "\n",
    "# The complete criterion defined in the task description.\n",
    "def score(mse_loss, sparsity, mse_weight=1.5, sparsity_weight=1.5):\n",
    "    \n",
    "    if type(mse_loss) == np.ndarray:\n",
    "        mse_loss[mse_loss > 1000] = 1000\n",
    "    else:\n",
    "        if mse_loss > 1000:\n",
    "            mse_loss = 1000\n",
    "            \n",
    "    score = (1 - mse_loss / 1000) ** mse_weight * sparsity**sparsity_weight\n",
    "    return score\n",
    "\n",
    "# Calculates the model's sparsity (ratio of zeroed parameters).\n",
    "def get_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name or \"bias\" in name:\n",
    "            total_params += param.numel()\n",
    "            zero_params += torch.sum(param == 0).item()\n",
    "            \n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity\n",
    "\n",
    "# Computes the Mean Squared Error (MSE).\n",
    "def compute_error(model, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = 0\n",
    "    num_of_el = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            outputs = model(x)\n",
    "            num_of_el += x.shape[0] * y.shape[1]\n",
    "            losses += model.loss(outputs, y, reduction=\"sum\")\n",
    "            \n",
    "    return losses / num_of_el\n",
    "\n",
    "# Scales the raw score to points.\n",
    "def points(score):\n",
    "    def scale(x, lower=0.085, upper=0.95, max_points=1.5):\n",
    "        scaled = min(max(x, lower), upper)\n",
    "        return (scaled - lower) / (upper - lower) * max_points\n",
    "    return scale(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c81d92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ###########################\n",
    "\n",
    "# Let's define our network's architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, input, target, reduction=\"mean\"):\n",
    "        mse_loss = nn.MSELoss(reduction=reduction)\n",
    "        return mse_loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ###########################\n",
    "\n",
    "# Initializing network weights\n",
    "def init_weights(m):\n",
    "    ''' Initialize the weights in the module m.'''\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "# Function to save the model's weights to a file - remember that your weights\n",
    "# file must be named: model_parameters.pkl\n",
    "def save_parameters(model, file_name=\"model_parameters.pkl\", to_file=True):\n",
    "\n",
    "    params_to_save = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        params_to_save[name] = param.to(\"cpu\")\n",
    "    \n",
    "    if not to_file:\n",
    "        return params_to_save\n",
    "    \n",
    "    with open(f\"{file_name}\", \"wb\") as f:\n",
    "        pickle.dump(params_to_save, f)\n",
    "\n",
    "# Function to load the model's weights from a file\n",
    "def load_parameters(model, file_name=\"model_parameters.pkl\", from_file=True, params=None):\n",
    "\n",
    "    if from_file:\n",
    "        with open(f\"{file_name}\", \"rb\") as f:\n",
    "            params_to_load = pickle.load(f)\n",
    "    else:\n",
    "        params_to_load = params\n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            param[...] = params_to_load[name].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc38fde",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ###########################\n",
    "\n",
    "# Function for training the model\n",
    "def train_model(model: nn.Module,\n",
    "              data_loaders: dict[str, DataLoader],\n",
    "              num_epochs: int,\n",
    "              optimizer: torch.optim.Optimizer,\n",
    "              verbose: bool = True\n",
    "              ) -> tuple[torch.Tensor, float]:\n",
    "    \"\"\"Function to train a model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network to be trained.\n",
    "        data_loaders (dict[str, DataLoader]): A dictionary containing DataLoaders for the training and validation sets.\n",
    "        num_epochs (int): The number of epochs for training.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for training the model.\n",
    "        verbose (bool, optional): If True, shows the training progress.\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, float]: A tuple containing the best set of model parameters\n",
    "                                    found during training and the corresponding loss value\n",
    "                                    on the validation set.\n",
    "    \"\"\"\n",
    "    if FINAL_EVALUATION_MODE:\n",
    "        verbose = False\n",
    "\n",
    "    best_epoch = None\n",
    "    best_params = None\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        _iter = 1\n",
    "        for inputs, targets in data_loaders['train']:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = model.loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose:\n",
    "                if _iter % 10 == 0:\n",
    "                    print(f\"Minibatch {_iter:>6}    |  loss {loss.item():>5.2f}  |\")\n",
    "\n",
    "            _iter +=1\n",
    "\n",
    "        val_loss = compute_error(model, data_loaders[\"valid\"])\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_epoch = epoch\n",
    "            best_val_loss = val_loss\n",
    "            best_params = [copy.deepcopy(p.detach().cpu()) for p in model.parameters()]\n",
    "\n",
    "        if verbose:\n",
    "            clear_output(True)\n",
    "            m = f\"After epoch {epoch:>2} | valid loss: {val_loss:>5.2f}\"\n",
    "            print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
    "\n",
    "    if best_params is not a None:\n",
    "        if verbose:\n",
    "            print(f\"\\nLoading best params on validation set in epoch {best_epoch} with loss {best_val_loss:.2f}\")\n",
    "        with torch.no_grad():\n",
    "            for param, best_param in zip(model.parameters(), best_params):\n",
    "                param[...] = best_param\n",
    "\n",
    "    return best_params, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3431da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "######################### DO NOT CHANGE THIS CELL ##########################\n",
    "initial_model = MLP().to(device)\n",
    "initial_model.apply(init_weights)\n",
    "\n",
    "optimizer = SGD(\n",
    "    initial_model.parameters(),\n",
    "    lr = 0.01,\n",
    "    momentum = 0.95,\n",
    "    weight_decay = 0.001\n",
    ")\n",
    "\n",
    "best_params, best_val_loss = train_model(initial_model, loaders, num_epochs=100, optimizer=optimizer, verbose=True)\n",
    "\n",
    "loss = compute_error(initial_model, loaders[\"valid\"])\n",
    "m = f\"| Validation loss: {loss:>5.2f} |\"\n",
    "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16ec92",
   "metadata": {},
   "source": [
    "### Example Solution 💡\n",
    "\n",
    "Below is a simple solution that is obviously not optimal. It's provided only to demonstrate how the entire notebook is intended to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7827898",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def starter_pruning_algorithm(model):\n",
    "    with torch.no_grad():\n",
    "        model.layers[0].weight[:, 0:2] = 0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b3226",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not FINAL_EVALUATION_MODE:\n",
    "    # Let's make a deep copy so we don't change the weights of the trained model\n",
    "    model_to_prune = copy.deepcopy(initial_model)\n",
    "\n",
    "    # Let's prune the weights with the example solution\n",
    "    model_to_prune = starter_pruning_algorithm(model_to_prune)\n",
    "\n",
    "    # Saving the model's parameters (we've changed the filename here, \n",
    "    # you should save yours as \"model_parameters.pkl\")\n",
    "    save_parameters(model_to_prune, \"starter_model_parameters.pkl\")\n",
    "\n",
    "    # Now let's see how to load the previously saved weights into a newly created model\n",
    "    new_model = MLP().to(device)\n",
    "    loss = compute_error(new_model, loaders[\"valid\"])\n",
    "    print(f\"The new model has a loss of {loss:.3f}\")\n",
    "\n",
    "    # Loading the model's parameters\n",
    "    load_parameters(new_model, \"starter_model_parameters.pkl\")\n",
    "    loss = compute_error(new_model, loaders[\"valid\"])\n",
    "    print(f\"After loading the parameters, the model has a loss of {loss:.3f}\")\n",
    "\n",
    "    mse = compute_error(new_model, loaders[\"valid\"])\n",
    "    sparsity = get_sparsity(new_model)\n",
    "\n",
    "    print(f\"Model MSE: {mse:.3f} Sparsity: {sparsity:.3f}\")\n",
    "    model_score = score(mse, sparsity)\n",
    "    print(f\"Your model's score is {model_score:.3f}!\")\n",
    "    print(f\"Your solution gets {points(model_score):.3f}/1.5 points!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd606dd",
   "metadata": {},
   "source": [
    "### Your Solution 🚀\n",
    "\n",
    "This section is the only place where you can change the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a41c2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def your_pruning_algorithm(model):\n",
    "    # TODO\n",
    "    pruned_model = starter_pruning_algorithm(model)\n",
    "    \n",
    "    # Saving the model's parameters \n",
    "    save_parameters(pruned_model, \"model_parameters.pkl\")\n",
    "    return pruned_model\n",
    "\n",
    "model_to_prune = copy.deepcopy(initial_model)\n",
    "your_pruning_algorithm(model_to_prune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c6f143",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The code below will be used to evaluate your solution. After you submit your solution, a function almost identical to the evaluate function below will be run on a test_data directory, which is available only to the graders.\n",
    "\n",
    "Before submitting, make sure that the entire notebook runs from start to finish without errors (also with the FINAL_EVALUATION_MODE flag set to True), requires no user interaction, and saves the weights to the model_parameters.pkl file after executing the \"Run All\" command. Also, check that validation_script.py returns the expected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49b3fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(X_test, y_test):\n",
    "    \"\"\"Validator\"\"\"\n",
    "    test_model = MLP().to(device)\n",
    "    load_parameters(test_model)\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    _test = InMemDataset(X_test, y_test, device)\n",
    "    test_loader = DataLoader(_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    mse = compute_error(test_model, test_loader)\n",
    "    sparsity = get_sparsity(test_model)\n",
    "\n",
    "    print(f\"Model had error: {mse:.3f} and sparsity: {sparsity:.3f}\")\n",
    "    model_score = score(mse, sparsity)\n",
    "\n",
    "    return model_score"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
